{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "128b4a15",
   "metadata": {
    "papermill": {
     "duration": 0.014218,
     "end_time": "2023-08-31T12:49:12.929567",
     "exception": false,
     "start_time": "2023-08-31T12:49:12.915349",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Binary Sentiment Analysis on IMDB Reviews Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911bdedf",
   "metadata": {
    "papermill": {
     "duration": 0.012023,
     "end_time": "2023-08-31T12:49:12.953903",
     "exception": false,
     "start_time": "2023-08-31T12:49:12.941880",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Libraries & Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e745062",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T12:49:12.981811Z",
     "iopub.status.busy": "2023-08-31T12:49:12.980927Z",
     "iopub.status.idle": "2023-08-31T12:49:23.525176Z",
     "shell.execute_reply": "2023-08-31T12:49:23.524289Z"
    },
    "papermill": {
     "duration": 10.561704,
     "end_time": "2023-08-31T12:49:23.528143",
     "exception": false,
     "start_time": "2023-08-31T12:49:12.966439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Env :  3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:40:32) [GCC 12.3.0]\n",
      "TensorFlow :  2.12.0\n"
     ]
    }
   ],
   "source": [
    "# Manage Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Libraris & Modules\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import re as regex\n",
    "import matplotlib.pyplot as plt\n",
    "from string import punctuation\n",
    "\n",
    "# TensorFlow Log Level\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# TensorFlow Libraries\n",
    "import tensorflow as tf\n",
    "\n",
    "# Environment/Versions\n",
    "print(\"Python Env : \", sys.version)\n",
    "print(\"TensorFlow : \", tf.__version__)\n",
    "\n",
    "# Random Generator Seed\n",
    "random_seed = 47"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bef488c",
   "metadata": {
    "papermill": {
     "duration": 0.012349,
     "end_time": "2023-08-31T12:49:23.552900",
     "exception": false,
     "start_time": "2023-08-31T12:49:23.540551",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Downloading & Exploring Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c41c309",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T12:49:23.582164Z",
     "iopub.status.busy": "2023-08-31T12:49:23.580918Z",
     "iopub.status.idle": "2023-08-31T12:50:05.490100Z",
     "shell.execute_reply": "2023-08-31T12:50:05.488712Z"
    },
    "papermill": {
     "duration": 41.92597,
     "end_time": "2023-08-31T12:50:05.493181",
     "exception": false,
     "start_time": "2023-08-31T12:49:23.567211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "84125825/84125825 [==============================] - 9s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Dataset Download Path\n",
    "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "\n",
    "# Retrieve File (and untar)\n",
    "dataset = tf.keras.utils.get_file(fname=\"aclImdb_v1\", \n",
    "                                  origin=url, \n",
    "                                  untar=True, \n",
    "                                  cache_dir=\".\", \n",
    "                                  cache_subdir=\"\")\n",
    "\n",
    "# Dataset Directory\n",
    "dataset_dir = os.path.join(os.path.dirname(dataset), \"aclImdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2f59d3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T12:50:05.536878Z",
     "iopub.status.busy": "2023-08-31T12:50:05.536446Z",
     "iopub.status.idle": "2023-08-31T12:50:05.545921Z",
     "shell.execute_reply": "2023-08-31T12:50:05.544585Z"
    },
    "papermill": {
     "duration": 0.034638,
     "end_time": "2023-08-31T12:50:05.548498",
     "exception": false,
     "start_time": "2023-08-31T12:50:05.513860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imdb.vocab', 'README', 'train', 'test', 'imdbEr.txt']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# List Dataset Sub-Directories & Files\n",
    "display(os.listdir(dataset_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a0956ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T12:50:05.590946Z",
     "iopub.status.busy": "2023-08-31T12:50:05.590506Z",
     "iopub.status.idle": "2023-08-31T12:50:05.598124Z",
     "shell.execute_reply": "2023-08-31T12:50:05.596286Z"
    },
    "papermill": {
     "duration": 0.031831,
     "end_time": "2023-08-31T12:50:05.600888",
     "exception": false,
     "start_time": "2023-08-31T12:50:05.569057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large Movie Review Dataset v1.0\n",
      "\n",
      "Overview\n",
      "\n",
      "This dataset contains movie reviews along with their associated binary\n",
      "sentiment polarity labels. It is intended to serve as a benchmark for\n",
      "sentiment classification. This document outlines how the dataset was\n",
      "gathered, and how to use the files provided. \n",
      "\n",
      "Dataset \n",
      "\n",
      "The core dataset contains 50,000 reviews split evenly into 25k train\n",
      "and 25k test sets. The overall distribution of labels is balanced (25k\n",
      "pos and 25k neg). We also include an additional 50,000 unlabeled\n",
      "documents for unsupervised learning. \n",
      "\n",
      "In the entire collection, no more than 30 reviews are allowed for any\n",
      "given movie because reviews for the same movie tend to have correlated\n",
      "ratings. Further, the train and test sets contain a disjoint set of\n",
      "movies, so no significant performance is obtained by memorizing\n",
      "movie-unique terms and their associated with observed labels.  In the\n",
      "labeled train/test sets, a negative review has a score <= 4 out of 10,\n",
      "and a positive review has a score >= 7 out of 10. Thus reviews with\n",
      "more neutral ratings are not included in the train/test sets. In the\n",
      "unsupervised set, reviews of any rating are included and there are an\n",
      "even number of reviews > 5 and <= 5.\n",
      "\n",
      "Files\n",
      "\n",
      "There are two top-level directories [train/, test/] corresponding to\n",
      "the training and test sets. Each contains [pos/, neg/] directories for\n",
      "the reviews with binary labels positive and negative. Within these\n",
      "directories, reviews are stored in text files named following the\n",
      "convention [[id]_[rating].txt] where [id] is a unique id and [rating] is\n",
      "the star rating for that review on a 1-10 scale. For example, the file\n",
      "[test/pos/200_8.txt] is the text for a positive-labeled test set\n",
      "example with unique id 200 and star rating 8/10 from IMDb. The\n",
      "[train/unsup/] directory has 0 for all ratings because the ratings are\n",
      "omitted for this portion of the dataset.\n",
      "\n",
      "We also include the IMDb URLs for each review in a separate\n",
      "[urls_[pos, neg, unsup].txt] file. A review with unique id 200 will\n",
      "have its URL on line 200 of this file. Due the ever-changing IMDb, we\n",
      "are unable to link directly to the review, but only to the movie's\n",
      "review page.\n",
      "\n",
      "In addition to the review text files, we include already-tokenized bag\n",
      "of words (BoW) features that were used in our experiments. These \n",
      "are stored in .feat files in the train/test directories. Each .feat\n",
      "file is in LIBSVM format, an ascii sparse-vector format for labeled\n",
      "data.  The feature indices in these files start from 0, and the text\n",
      "tokens corresponding to a feature index is found in [imdb.vocab]. So a\n",
      "line with 0:7 in a .feat file means the first word in [imdb.vocab]\n",
      "(the) appears 7 times in that review.\n",
      "\n",
      "LIBSVM page for details on .feat file format:\n",
      "http://www.csie.ntu.edu.tw/~cjlin/libsvm/\n",
      "\n",
      "We also include [imdbEr.txt] which contains the expected rating for\n",
      "each token in [imdb.vocab] as computed by (Potts, 2011). The expected\n",
      "rating is a good way to get a sense for the average polarity of a word\n",
      "in the dataset.\n",
      "\n",
      "Citing the dataset\n",
      "\n",
      "When using this dataset please cite our ACL 2011 paper which\n",
      "introduces it. This paper also contains classification results which\n",
      "you may want to compare against.\n",
      "\n",
      "\n",
      "@InProceedings{maas-EtAl:2011:ACL-HLT2011,\n",
      "  author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n",
      "  title     = {Learning Word Vectors for Sentiment Analysis},\n",
      "  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n",
      "  month     = {June},\n",
      "  year      = {2011},\n",
      "  address   = {Portland, Oregon, USA},\n",
      "  publisher = {Association for Computational Linguistics},\n",
      "  pages     = {142--150},\n",
      "  url       = {http://www.aclweb.org/anthology/P11-1015}\n",
      "}\n",
      "\n",
      "References\n",
      "\n",
      "Potts, Christopher. 2011. On the negativity of negation. In Nan Li and\n",
      "David Lutz, eds., Proceedings of Semantics and Linguistic Theory 20,\n",
      "636-659.\n",
      "\n",
      "Contact\n",
      "\n",
      "For questions/comments/corrections please contact Andrew Maas\n",
      "amaas@cs.stanford.edu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Review Readme File\n",
    "with open(os.path.join(dataset_dir, 'README'), 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2f97764",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T12:50:05.645765Z",
     "iopub.status.busy": "2023-08-31T12:50:05.645035Z",
     "iopub.status.idle": "2023-08-31T12:50:05.655931Z",
     "shell.execute_reply": "2023-08-31T12:50:05.654685Z"
    },
    "papermill": {
     "duration": 0.036234,
     "end_time": "2023-08-31T12:50:05.658303",
     "exception": false,
     "start_time": "2023-08-31T12:50:05.622069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg',\n",
       " 'urls_neg.txt',\n",
       " 'unsup',\n",
       " 'unsupBow.feat',\n",
       " 'urls_pos.txt',\n",
       " 'pos',\n",
       " 'labeledBow.feat',\n",
       " 'urls_unsup.txt']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['neg', 'urls_neg.txt', 'urls_pos.txt', 'pos', 'labeledBow.feat']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train & Test Directories\n",
    "display(os.listdir(f\"{dataset_dir}/train\"))\n",
    "display(os.listdir(f\"{dataset_dir}/test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53e108a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T12:50:05.703536Z",
     "iopub.status.busy": "2023-08-31T12:50:05.702887Z",
     "iopub.status.idle": "2023-08-31T12:50:05.711794Z",
     "shell.execute_reply": "2023-08-31T12:50:05.710583Z"
    },
    "papermill": {
     "duration": 0.034858,
     "end_time": "2023-08-31T12:50:05.714217",
     "exception": false,
     "start_time": "2023-08-31T12:50:05.679359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg',\n",
       " 'urls_neg.txt',\n",
       " 'unsup',\n",
       " 'unsupBow.feat',\n",
       " 'urls_pos.txt',\n",
       " 'pos',\n",
       " 'labeledBow.feat',\n",
       " 'urls_unsup.txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Data Directory\n",
    "train_dir = os.path.join(dataset_dir, \"train\")\n",
    "train_dir_items = os.listdir(train_dir)\n",
    "train_dir_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb0d2341",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T12:50:05.761702Z",
     "iopub.status.busy": "2023-08-31T12:50:05.761021Z",
     "iopub.status.idle": "2023-08-31T12:50:05.768379Z",
     "shell.execute_reply": "2023-08-31T12:50:05.767390Z"
    },
    "papermill": {
     "duration": 0.034776,
     "end_time": "2023-08-31T12:50:05.770969",
     "exception": false,
     "start_time": "2023-08-31T12:50:05.736193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'urls_neg.txt', 'urls_pos.txt', 'pos', 'labeledBow.feat']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing Data Directory\n",
    "test_dir = os.path.join(dataset_dir, \"test\")\n",
    "os.listdir(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd1f9ba7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T12:50:05.817407Z",
     "iopub.status.busy": "2023-08-31T12:50:05.816990Z",
     "iopub.status.idle": "2023-08-31T12:50:05.834070Z",
     "shell.execute_reply": "2023-08-31T12:50:05.832498Z"
    },
    "papermill": {
     "duration": 0.043285,
     "end_time": "2023-08-31T12:50:05.836582",
     "exception": false,
     "start_time": "2023-08-31T12:50:05.793297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File : 1223_7.txt\n",
      "\n",
      "about a year and a half ago my dad told me about The French Doors. i thought it sounded interesting enough but i didn't try to find it anywhere. Then about a year ago i remembered that film and thought \"hey why not\" and tried finding it on the internet. eventually after about a week of looking i found it on atom films. i called my dad over to the computer and said to him\" hey dad I've found that creepy film you told me about ages ago!\" He smiled at me, turned round turned off the lights so it was pitch black apart from the computer screen and told me to watch it. I started off fine...Then when he started getting worried about whatever was there i found it very unnerving. at the end i pushed back my chair and stood up...it made me jump!:P if you haven't seen this film i highly recommend you do because it is well worth it. even after the fourth or fifth time its still unsettling.<br /><br />GREAT FILM!\n"
     ]
    }
   ],
   "source": [
    "# View a sample positive review.\n",
    "train_files = os.listdir(os.path.join(train_dir, \"pos\"))\n",
    "sample_fname = train_files[2]\n",
    "print(f\"File : {sample_fname}\\n\")\n",
    "with open(os.path.join(train_dir, f\"pos/{sample_fname}\")) as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e1e3613",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T12:50:05.883836Z",
     "iopub.status.busy": "2023-08-31T12:50:05.883043Z",
     "iopub.status.idle": "2023-08-31T12:50:05.964253Z",
     "shell.execute_reply": "2023-08-31T12:50:05.962515Z"
    },
    "papermill": {
     "duration": 0.107774,
     "end_time": "2023-08-31T12:50:05.967501",
     "exception": false,
     "start_time": "2023-08-31T12:50:05.859727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.text_dataset_from_directory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10db9cb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T12:50:06.013327Z",
     "iopub.status.busy": "2023-08-31T12:50:06.012306Z",
     "iopub.status.idle": "2023-08-31T12:50:13.958487Z",
     "shell.execute_reply": "2023-08-31T12:50:13.957703Z"
    },
    "papermill": {
     "duration": 7.972524,
     "end_time": "2023-08-31T12:50:13.961600",
     "exception": false,
     "start_time": "2023-08-31T12:50:05.989076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imdb.vocab', 'README', 'train', 'test', 'imdbEr.txt', 'train_unsup']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['neg', 'urls_neg.txt', 'urls_pos.txt', 'pos', 'labeledBow.feat']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['unsup', 'unsupBow.feat', 'urls_unsup.txt']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare Training Directory as per 'text_dataset_from_directory' Requirements.\n",
    "# -----------------------------------------------------------------------------\n",
    "# Create New Directory for Unsupervised Data\n",
    "train_unsup_dir = os.path.join(dataset_dir, \"train_unsup\")\n",
    "if not os.path.exists(train_unsup_dir):\n",
    "    os.makedirs(train_unsup_dir)\n",
    "else:\n",
    "    pass\n",
    "display(os.listdir(dataset_dir))\n",
    "# Collect Unsupervised Data Files and Directories\n",
    "file_list = [_ for _ in train_dir_items if \"unsup\" in _]\n",
    "# Source & Destination Directories\n",
    "source_dir = train_dir\n",
    "destination_dir = train_unsup_dir\n",
    "# Move Files and Directories\n",
    "for file in file_list:\n",
    "    source_file = os.path.join(source_dir, file)\n",
    "    destination_file = os.path.join(destination_dir, file)\n",
    "    # Move as per Directory/File\n",
    "    if os.path.isdir(source_file):\n",
    "        shutil.copytree(source_file, destination_file)\n",
    "        shutil.rmtree(source_file)\n",
    "    else:\n",
    "        shutil.move(source_file, destination_file)\n",
    "\n",
    "# Review Training & Unsupervised Training Data Directories\n",
    "display(os.listdir(train_dir))\n",
    "display(os.listdir(train_unsup_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6233c3",
   "metadata": {
    "papermill": {
     "duration": 0.021425,
     "end_time": "2023-08-31T12:50:14.005317",
     "exception": false,
     "start_time": "2023-08-31T12:50:13.983892",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training, Validation & Testing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f19de155",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T12:50:14.051715Z",
     "iopub.status.busy": "2023-08-31T12:50:14.051279Z",
     "iopub.status.idle": "2023-08-31T12:50:20.716650Z",
     "shell.execute_reply": "2023-08-31T12:50:20.715573Z"
    },
    "papermill": {
     "duration": 6.691632,
     "end_time": "2023-08-31T12:50:20.719312",
     "exception": false,
     "start_time": "2023-08-31T12:50:14.027680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset :\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n",
      "\n",
      "\n",
      "Validation Dataset :\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n",
      "\n",
      "\n",
      "Testing Dataset :\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Training Dataset\n",
    "print(\"Training Dataset :\")\n",
    "train_ds = tf.keras.utils.text_dataset_from_directory(directory=train_dir, \n",
    "                                                      batch_size=8, \n",
    "                                                      validation_split=0.2, \n",
    "                                                      subset='training', \n",
    "                                                      seed=random_seed)\n",
    "\n",
    "# Validation Dataset\n",
    "print(\"\\n\")\n",
    "print(\"Validation Dataset :\")\n",
    "val_ds = tf.keras.utils.text_dataset_from_directory(directory=train_dir, \n",
    "                                                    batch_size=8, \n",
    "                                                    validation_split=0.2, \n",
    "                                                    subset='validation', \n",
    "                                                    seed=random_seed)\n",
    "\n",
    "# Testing Dataset\n",
    "print(\"\\n\")\n",
    "print(\"Testing Dataset :\")\n",
    "test_ds = tf.keras.utils.text_dataset_from_directory(directory=test_dir, \n",
    "                                                     batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8db2643c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T12:50:20.776008Z",
     "iopub.status.busy": "2023-08-31T12:50:20.775467Z",
     "iopub.status.idle": "2023-08-31T12:50:20.927549Z",
     "shell.execute_reply": "2023-08-31T12:50:20.926399Z"
    },
    "papermill": {
     "duration": 0.178645,
     "end_time": "2023-08-31T12:50:20.930173",
     "exception": false,
     "start_time": "2023-08-31T12:50:20.751528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Element 1 (Labels)  : [8]\n",
      "Dataset Element 1 (Reviews) : [8]\n",
      "\n",
      "LABEL  : 0\n",
      "REVIEW : b\"I wouldn't say this is a *bad* movie. Unfortunately for me, I get the feeling that the more you know about fencing, the worse it gets simply due to the fact that it becomes totally unrealistic. I've been fencing since i was 14 years old, and this movie portrays it very poorly. F. Murray Abraham is good (and appears to have some fencing background), but most of the other actors--especially the students--just seem to be lost.\"\n",
      "--------------------------------------------------------------------------------\n",
      "LABEL  : 1\n",
      "REVIEW : b'Family problems abound in real life and that is what this movie is about. Love can hold the members together through out the ordeals and trials and that is what this movie is about. One man, Daddy, has the maturity and fortitude to sustain the family in the face of adversity. The kids grow up,one all be it, in the hard way, to realize that no matter how old they or a parent is, the parent still loves their children and are willing to provide them a cushion when they fall. ALL the actors portraying their characters did outstanding performances. Yes, I shed a tear along the way knowing I had had similar experiences both as a young adult and later as a parent. This true to life is one which every young adult, and parent, would do well to see, although some will not realize it until they too are parents. A must see for those who care about their families.'\n",
      "--------------------------------------------------------------------------------\n",
      "LABEL  : 1\n",
      "REVIEW : b'In \"Anne of Green Gables\" (1934), Marilla Cuthbert (Helen Westley) and Matthew Cuthbert (O.P. Heggie), middle-aged siblings who live together at Green Gables, a farm in Avonlea, on Prince Edward Island, decide to adopt a boy from distant orphanage to help on their farm. But the orphan sent to them is a precocious girl of 14 named Anne Shirley (Dawn Evelyn Paris-a veteran of Disney\\'s series of \"Alice\" shorts who later would adopt her character\\'s name). <br /><br />Anne was only 11 in Lucy Maude Montgomery\\'s source novel but the same actress could not credibly go from 11 to college age during the course of the story. The movie suffers somewhat from this concession, as many of Anne\\'s reactions and much of what she says are more entertaining coming from an eleven-year-old that from a teenager. As in the book, Anne is bright and quick, eager to please but dissatisfied with her name, her build, her freckles, and her long red hair. Being a child of imagination, however, Anne takes much joy in life, and adapts quickly to her new family and the environment of Prince Edward Island.<br /><br />In fact Anne is the original \"Teenage Drama Queen\" and the film\\'s screenwriter elected to focus on this aspect of her character. Which transformed the basic genre from mildly amusing family drama to comedy. A change that delighted audiences and that continues to frustrate reader purists. <br /><br />Since the comedy is very much in the spirit of the Montgomery\\'s story I can see no reason to take issue with the changes, but let this serve as fair warning to anyone expecting a totally faithful adaptation. The comedy element is the strength of the film as it is one of the earliest self-reflexive parodies of Hollywood conventions. The actress Anne Shirley was one of Hollywood\\'s all- time beauties and the film is in black and white. So much of the amusement is in seeing the title character\\'s endless laments about her appearance and hair color contradicted by what is appearing on the screen. Anne regularly regales her no nonsense rural companions with melodramatic lines like: \"If you refuse it will be a lifelong sorrow to me\". Perhaps the funniest moment is when she corrects the spelling of her name on the classroom blackboard. <br /><br />Tom Brown does a nice job as Anne\\'s love interest Gilbert Blythe and Sara Haden steals all the scenes in which she appears as the Cuthbert\\'s pompous neighbor. <br /><br />Then again, what do I know? I\\'m only a child.'\n",
      "--------------------------------------------------------------------------------\n",
      "LABEL  : 1\n",
      "REVIEW : b'Why did it sound like the husband kept calling her Appy ? It ruined a great episode and so I can only give it a 6. Proper grammar and pronunciation are essential to a film.<br /><br />It was very Hellraiser what with all the skin ripping though I dunno how anyone can survive without skin the skin is a vital organ to the body the biggest organ actually and without we would die. The more a horror film is true the more creepy it can be and more entertaining.<br /><br />I do admit though that the stories from the great horror directors are very disappointing and very mediocre. <br /><br />6/10 come on Yankies get your English up to par !'\n",
      "--------------------------------------------------------------------------------\n",
      "LABEL  : 0\n",
      "REVIEW : b'I have to agree with most everyone\\'s opinion that this show was poorly produced as well as written.The acting was not much more above the lower production values however I feel an actor can only rely on the material provided to them and make the best of it. In keeping with this thought I feel it is important to point out that one actor has risen and persevered well beyond this campy to tasteless production to have become a respectable and quite talented performer.I am referring to Laura Harris a Canadian born actor who has etched her way through many poorly produced shows and movies to find a place on the HBO hit \"Dead Like Me\" where she plays the role of Daisy Adair and to her credit she handles this role in an efficient manner.I remember having a typical boyhood crush on the young actress during this series where she played Ashley a soft spoken yet intelligent 7th grader.I felt as though if anyone might \"make it\" from this series it surely would be Laura Harris and true to her nature she did excel in the acting field to win the respect of many producers who now recognize her for her talent as well as unique Nordic blond allure. If you ever do have the opportunity to view this series I recommend that you have something epic to watch after wards such as the \\'Godfather\\' or perhaps \\'Beaches\\' in order to remind yourself that there is after all a great deal of true production integrity and value out there and that this series is only a low-budget reminder of what Laura Harris can simply state about her time on the show and I bet she would quote many a young actors words of defense by saying \"It\\'s a start!\"'\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Review Dataset\n",
    "for x, y in train_ds.take(1):\n",
    "    print(f\"Dataset Element 1 (Labels)  : {tf.shape(y)}\")\n",
    "    print(f\"Dataset Element 1 (Reviews) : {tf.shape(x)}\\n\")\n",
    "    for i in range(5):\n",
    "        tf.print(f\"LABEL  : {y[i]}\")\n",
    "        tf.print(f\"REVIEW : {x[i]}\")\n",
    "        tf.print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c85a59c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T12:50:20.979271Z",
     "iopub.status.busy": "2023-08-31T12:50:20.978857Z",
     "iopub.status.idle": "2023-08-31T12:50:20.985211Z",
     "shell.execute_reply": "2023-08-31T12:50:20.984267Z"
    },
    "papermill": {
     "duration": 0.033454,
     "end_time": "2023-08-31T12:50:20.987401",
     "exception": false,
     "start_time": "2023-08-31T12:50:20.953947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Class Names Corresponding to Index (as Numerical Label)\n",
    "display(train_ds.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d45e3c",
   "metadata": {
    "papermill": {
     "duration": 0.023444,
     "end_time": "2023-08-31T12:50:21.034471",
     "exception": false,
     "start_time": "2023-08-31T12:50:21.011027",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ac8ce8",
   "metadata": {
    "papermill": {
     "duration": 0.023414,
     "end_time": "2023-08-31T12:50:21.081478",
     "exception": false,
     "start_time": "2023-08-31T12:50:21.058064",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Custom Standardization Function\n",
    "\n",
    "Removing Punctuations & HTML Elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bc071e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T12:50:21.132256Z",
     "iopub.status.busy": "2023-08-31T12:50:21.131529Z",
     "iopub.status.idle": "2023-08-31T12:50:21.137838Z",
     "shell.execute_reply": "2023-08-31T12:50:21.137065Z"
    },
    "papermill": {
     "duration": 0.033743,
     "end_time": "2023-08-31T12:50:21.139931",
     "exception": false,
     "start_time": "2023-08-31T12:50:21.106188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function Definition : Remove HTML Tags & Punctuations\n",
    "def custom_standardize(input_data):\n",
    "    \"\"\"Remove HTML Tags & Punctuations\"\"\"\n",
    "    \n",
    "    # Convert to Lowercase\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    \n",
    "    # Remove the '<br />' Tag\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n",
    "    \n",
    "    # Remove Punctuations\n",
    "    stripped_html_punc = tf.strings.regex_replace(stripped_html,\n",
    "        \"[%s]\" % regex.escape(punctuation), \"\"\n",
    "    )\n",
    "    \n",
    "    return stripped_html_punc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecefddd0",
   "metadata": {
    "papermill": {
     "duration": 0.023244,
     "end_time": "2023-08-31T12:50:21.186658",
     "exception": false,
     "start_time": "2023-08-31T12:50:21.163414",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Tokenization & Vectorization\n",
    "\n",
    "- Custom function for Standardization\n",
    "- Splitting strings into tokens. --> tf.keras.layers.TextVectorization()\n",
    "- Converting tokens into numbers for neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff5d7f2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T12:50:21.236459Z",
     "iopub.status.busy": "2023-08-31T12:50:21.235761Z",
     "iopub.status.idle": "2023-08-31T12:50:21.303924Z",
     "shell.execute_reply": "2023-08-31T12:50:21.302518Z"
    },
    "papermill": {
     "duration": 0.095638,
     "end_time": "2023-08-31T12:50:21.306406",
     "exception": false,
     "start_time": "2023-08-31T12:50:21.210768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Features(Tokens) in Entire Dataset :  89600\n",
      "Maximum Output Sequence Length of Vectorization Layer :  250\n"
     ]
    }
   ],
   "source": [
    "# Calculate Maximum Features Value\n",
    "# --------------------------------\n",
    "# Collect all Word Tokens provided in Dataset\n",
    "vocab_tokens = list()\n",
    "with open(os.path.join(dataset_dir, \"imdb.vocab\"), \"r\") as f:\n",
    "    for line in f:\n",
    "        vocab_tokens.append(line.strip())\n",
    "vocab_tokens = set(vocab_tokens)       \n",
    "\n",
    "# Calc. Max. Features rounded to next hundred\n",
    "max_features = round(len(vocab_tokens)+100, -2)\n",
    "\n",
    "# Delete Token Object\n",
    "del vocab_tokens\n",
    "\n",
    "# Display Max. Features\n",
    "print(\"Maximum Features(Tokens) in Entire Dataset : \", max_features)\n",
    "\n",
    "# Set Maximum Sequence Length\n",
    "# ---------------------------\n",
    "max_seq_len = 250\n",
    "print(\"Maximum Output Sequence Length of Vectorization Layer : \", max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68d7d957",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T12:50:21.356181Z",
     "iopub.status.busy": "2023-08-31T12:50:21.355777Z",
     "iopub.status.idle": "2023-08-31T12:50:21.387968Z",
     "shell.execute_reply": "2023-08-31T12:50:21.386718Z"
    },
    "papermill": {
     "duration": 0.060274,
     "end_time": "2023-08-31T12:50:21.390422",
     "exception": false,
     "start_time": "2023-08-31T12:50:21.330148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.preprocessing.text_vectorization.TextVectorization at 0x7fc45a61a1a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Vectorization Layer\n",
    "T_Vect = tf.keras.layers.TextVectorization(standardize=custom_standardize, \n",
    "                                           max_tokens=max_features, \n",
    "                                           output_mode=\"int\", \n",
    "                                           output_sequence_length=max_seq_len)\n",
    "display(T_Vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3090657f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T12:50:21.440739Z",
     "iopub.status.busy": "2023-08-31T12:50:21.440333Z",
     "iopub.status.idle": "2023-08-31T12:50:26.705046Z",
     "shell.execute_reply": "2023-08-31T12:50:26.703793Z"
    },
    "papermill": {
     "duration": 5.292501,
     "end_time": "2023-08-31T12:50:26.707466",
     "exception": false,
     "start_time": "2023-08-31T12:50:21.414965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.preprocessing.text_vectorization.TextVectorization at 0x7fc45a61a1a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit State of Preprocessing Layer to the Dataset\n",
    "training_text = train_ds.map(lambda x, _ : x)\n",
    "T_Vect.adapt(training_text)\n",
    "display(T_Vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6621c867",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T12:50:26.757972Z",
     "iopub.status.busy": "2023-08-31T12:50:26.757521Z",
     "iopub.status.idle": "2023-08-31T12:50:27.549603Z",
     "shell.execute_reply": "2023-08-31T12:50:27.548419Z"
    },
    "papermill": {
     "duration": 0.82051,
     "end_time": "2023-08-31T12:50:27.552452",
     "exception": false,
     "start_time": "2023-08-31T12:50:26.731942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Element 1 (Labels)  : [8]\n",
      "Dataset Element 1 (Reviews) : [8]\n",
      "\n",
      "LABEL  : 0\n",
      "REVIEW : b\"This film turned up on local TV here in South Africa recently and I thought that I'd warn even those who enjoy watching B grade bad movies (which I do)that this is not even amusing. The plot concerns a couple visiting a house in the country. Some strangers appear and .... The problem is that most of the film, obviously shot in the early seventies, consists of extreme wide shots of people walking, in real time and awfully slowly, from A to B. This makes the film tedious in the extreme and the expected blood and gore payoff just never happens. I am really curious - how many people have actually watched this from beginning to end?\"\n",
      "--------------------------------------------------------------------------------\n",
      "VECTORIZED REVIEW :\n",
      "tf.Tensor(\n",
      "[[   11    19   695    54    20   686   246   128     8  1207  2334   998\n",
      "      3    10   197    12   441  2792    53   143    35   350   146   959\n",
      "   1467    79    93    61    10 86342    11     7    21    53  1130     2\n",
      "    111  3268     4   359  4815     4   314     8     2   691    47  4820\n",
      "    926     3     2   429     7    12    87     5     2    19   526   317\n",
      "      8     2   390  3909  3026     5  1468  2188   652     5    83  1259\n",
      "      8   144    59     3  4861  1310    36     4     6   959    11   160\n",
      "      2    19  2297     8     2  1468     3     2   840   531     3   659\n",
      "   6257    41   109   549    10   236    63  1889    86   105    83    25\n",
      "    156   281    11    36   437     6   126     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0]], shape=(1, 250), dtype=int64)\n",
      "--------------------------------------------------------------------------------\n",
      "First Token :  tf.Tensor(11, shape=(), dtype=int64)\n",
      "Corresponding Vocabulary :  this\n",
      "Vocabulary Size :  89600\n"
     ]
    }
   ],
   "source": [
    "# Review Vectorization Layer's Output\n",
    "for x, y in train_ds.take(1):\n",
    "    print(f\"Dataset Element 1 (Labels)  : {tf.shape(y)}\")\n",
    "    print(f\"Dataset Element 1 (Reviews) : {tf.shape(x)}\\n\")\n",
    "    for i in range(1):\n",
    "        tf.print(f\"LABEL  : {y[i]}\")\n",
    "        tf.print(f\"REVIEW : {x[i]}\")\n",
    "        tf.print(\"-\"*80)\n",
    "        tf.print(f\"VECTORIZED REVIEW :\")\n",
    "        vectorized = T_Vect(tf.expand_dims(x[i], -1))\n",
    "        print(vectorized)\n",
    "        tf.print(\"-\"*80)\n",
    "        print(\"First Token : \", vectorized[0][0])\n",
    "        print(\"Corresponding Vocabulary : \", T_Vect.get_vocabulary()[vectorized[0][0]])\n",
    "        print(\"Vocabulary Size : \", len(T_Vect.get_vocabulary()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223480d2",
   "metadata": {
    "papermill": {
     "duration": 0.02529,
     "end_time": "2023-08-31T12:50:27.603356",
     "exception": false,
     "start_time": "2023-08-31T12:50:27.578066",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Finalizing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5a06e1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T12:50:27.658216Z",
     "iopub.status.busy": "2023-08-31T12:50:27.657805Z",
     "iopub.status.idle": "2023-08-31T12:50:27.663162Z",
     "shell.execute_reply": "2023-08-31T12:50:27.662161Z"
    },
    "papermill": {
     "duration": 0.034261,
     "end_time": "2023-08-31T12:50:27.665322",
     "exception": false,
     "start_time": "2023-08-31T12:50:27.631061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to Map Vectorization to Dataset\n",
    "def vectorize(inputs, labels):\n",
    "    return T_Vect(inputs), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7be6d08c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T12:50:27.718545Z",
     "iopub.status.busy": "2023-08-31T12:50:27.718174Z",
     "iopub.status.idle": "2023-08-31T12:50:27.909959Z",
     "shell.execute_reply": "2023-08-31T12:50:27.908971Z"
    },
    "papermill": {
     "duration": 0.221771,
     "end_time": "2023-08-31T12:50:27.912643",
     "exception": false,
     "start_time": "2023-08-31T12:50:27.690872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare Training, Testing and Validation Datasets\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE).map(vectorize)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE).map(vectorize)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE).map(vectorize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcae195",
   "metadata": {
    "papermill": {
     "duration": 0.024324,
     "end_time": "2023-08-31T12:50:27.961906",
     "exception": false,
     "start_time": "2023-08-31T12:50:27.937582",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80494d8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T12:50:28.012998Z",
     "iopub.status.busy": "2023-08-31T12:50:28.012562Z",
     "iopub.status.idle": "2023-08-31T12:50:28.142705Z",
     "shell.execute_reply": "2023-08-31T12:50:28.141669Z"
    },
    "papermill": {
     "duration": 0.158359,
     "end_time": "2023-08-31T12:50:28.144859",
     "exception": false,
     "start_time": "2023-08-31T12:50:27.986500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Sequential_Text_Classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 16)          1433616   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, 16)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 16)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,433,633\n",
      "Trainable params: 1,433,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Token Embedding Depth\n",
    "embedding_dim = 16\n",
    "\n",
    "# Define Model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(max_features + 1, embedding_dim),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1)],\n",
    "    name=\"Sequential_Text_Classification\"\n",
    ")\n",
    "\n",
    "# Compile Model\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer='adam',\n",
    "              metrics=tf.metrics.BinaryAccuracy(threshold=0.0))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1114e6f6",
   "metadata": {
    "papermill": {
     "duration": 0.026694,
     "end_time": "2023-08-31T12:50:28.198038",
     "exception": false,
     "start_time": "2023-08-31T12:50:28.171344",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5fc99713",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T12:50:28.253519Z",
     "iopub.status.busy": "2023-08-31T12:50:28.252832Z",
     "iopub.status.idle": "2023-08-31T12:56:29.461196Z",
     "shell.execute_reply": "2023-08-31T12:56:29.460079Z"
    },
    "papermill": {
     "duration": 361.239641,
     "end_time": "2023-08-31T12:56:29.464117",
     "exception": false,
     "start_time": "2023-08-31T12:50:28.224476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 34s 13ms/step - loss: 0.5877 - binary_accuracy: 0.7564 - val_loss: 0.4621 - val_binary_accuracy: 0.8222\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 33s 13ms/step - loss: 0.3713 - binary_accuracy: 0.8661 - val_loss: 0.3503 - val_binary_accuracy: 0.8560\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 33s 13ms/step - loss: 0.2767 - binary_accuracy: 0.8998 - val_loss: 0.3121 - val_binary_accuracy: 0.8736\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 32s 13ms/step - loss: 0.2221 - binary_accuracy: 0.9214 - val_loss: 0.2963 - val_binary_accuracy: 0.8824\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 33s 13ms/step - loss: 0.1830 - binary_accuracy: 0.9360 - val_loss: 0.2903 - val_binary_accuracy: 0.8830\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 32s 13ms/step - loss: 0.1520 - binary_accuracy: 0.9512 - val_loss: 0.2922 - val_binary_accuracy: 0.8806\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 33s 13ms/step - loss: 0.1276 - binary_accuracy: 0.9606 - val_loss: 0.2944 - val_binary_accuracy: 0.8806\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 33s 13ms/step - loss: 0.1056 - binary_accuracy: 0.9677 - val_loss: 0.3037 - val_binary_accuracy: 0.8794\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 33s 13ms/step - loss: 0.0873 - binary_accuracy: 0.9744 - val_loss: 0.3201 - val_binary_accuracy: 0.8782\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 33s 13ms/step - loss: 0.0724 - binary_accuracy: 0.9794 - val_loss: 0.3320 - val_binary_accuracy: 0.8760\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train_ds, validation_data=val_ds, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0474a0",
   "metadata": {
    "papermill": {
     "duration": 0.552918,
     "end_time": "2023-08-31T12:56:30.556477",
     "exception": false,
     "start_time": "2023-08-31T12:56:30.003559",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "611123d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T12:56:31.701586Z",
     "iopub.status.busy": "2023-08-31T12:56:31.701213Z",
     "iopub.status.idle": "2023-08-31T12:56:37.254114Z",
     "shell.execute_reply": "2023-08-31T12:56:37.252737Z"
    },
    "papermill": {
     "duration": 6.164727,
     "end_time": "2023-08-31T12:56:37.256746",
     "exception": false,
     "start_time": "2023-08-31T12:56:31.092019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.3610 - binary_accuracy: 0.8659\n",
      "Loss     : 0.36\n",
      "Accuracy : 86.59 %\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "\n",
    "print(f\"Loss     : {round(loss, 2)}\")\n",
    "print(f\"Accuracy : {round(accuracy*100, 2)} %\")"
   ]
  }
 ],
 "kernelspec": {
  "display_name": "Python 3",
  "language": "python",
  "name": "python3"
 },
 "language_info": {
  "codemirror_mode": {
   "name": "ipython",
   "version": 3
  },
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "nbconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": "3.6.4"
 },
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 458.890627,
   "end_time": "2023-08-31T12:56:39.730120",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-31T12:49:00.839493",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
